{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1251c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Application packages\n",
    "import datetime as dt\n",
    "import glob\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import ray\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import hytools as ht\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pystac\n",
    "import subprocess\n",
    "\n",
    "# stage_in packages\n",
    "from unity_sds_client.resources.collection import Collection\n",
    "\n",
    "# stage_out packages\n",
    "from datetime import datetime, timezone\n",
    "from unity_sds_client.resources.dataset import Dataset\n",
    "from unity_sds_client.resources.data_file import DataFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ac7f2d",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_stac_collection_file = '/unity/ads/input_collections/TRAIT_MERGE/catalog.json' # type: stage-in\n",
    "output_stac_catalog_dir    = '/unity/ads/outputs/SBG-L2B_VEGBIOCHEM'                    # type: stage-out\n",
    "\n",
    "experimental = False\n",
    "crid = \"000\"\n",
    "veg_cover = 0.5\n",
    "gdal_dir = \"/home/jovyan/conda-envs/sister-trait/bin\"\n",
    "\n",
    "#For eventual catalogging of this file in the unity environment\n",
    "output_collection=\"urn:nasa:unity:unity:dev:SBG-L2B_VEGBIOCHEM___1\"\n",
    "\n",
    "#optional variables\n",
    "temp_work_dir = \"/unity/ads/temp/SBG-L2B_VEGBIOCHEM\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7fa38",
   "metadata": {},
   "source": [
    "# Import Files from STAC Item Collection\n",
    "\n",
    "Load filenames from the stage_in STAC item collection file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a09d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/unity/ads/input_collections/TRAIT_MERGE/./SISTER_EMIT_L2A_CORFL_20230807T182755_001.bin',\n",
       " '/unity/ads/input_collections/TRAIT_MERGE/./SISTER_EMIT_L2A_CORFL_20230807T182755_001.hdr',\n",
       " '/unity/ads/input_collections/TRAIT_MERGE/./SISTER_EMIT_L2B_FRCOV_20230807T182755_001.tif']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_collection = Collection(output_collection)\n",
    "inp_collection = Collection.from_stac(input_stac_collection_file)\n",
    "data_filenames = inp_collection.data_locations([\"data\"])\n",
    "\n",
    "data_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9164de-a9ce-4899-8a37-bcebaefdb788",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_filenames:\n",
    "    if \".hdr\" in df:\n",
    "        reflectance_hdr_file = df\n",
    "    elif \".bin\" in df:\n",
    "        reflectance_file = df\n",
    "    elif \".tif\" in df:\n",
    "        frcov_file = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245eb45b-3cae-4fdc-99a1-bd712c093b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 16:57:19,166 INFO: Starting trait_estimate.py\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(output_stac_catalog_dir):\n",
    "    os.mkdir(output_stac_catalog_dir)\n",
    "\n",
    "if not os.path.exists(temp_work_dir):\n",
    "    os.mkdir(temp_work_dir)\n",
    "\n",
    "# Set up console logging using root logger\n",
    "logging.basicConfig(format=\"%(asctime)s %(levelname)s: %(message)s\", level=logging.INFO)\n",
    "logger = logging.getLogger(\"sister-trait-estimate\")\n",
    "# Set up file handler logging\n",
    "handler = logging.FileHandler(f\"{output_stac_catalog_dir}/pge_run.log\")\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter(\"%(asctime)s %(levelname)s [%(module)s]: %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.info(\"Starting trait_estimate.py\")\n",
    "\n",
    "if not os.path.exists(\"models\"):\n",
    "    logger.error(\"Can't find modles directory!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd0aa78-d761-4ec5-81dd-1b443eed998d",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e35774c-9102-447e-9965-3c54756ed22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_description_from_trait(trait, model_jsons):\n",
    "    for model in model_jsons:\n",
    "        if trait == model[\"short_name\"].upper():\n",
    "            return model[\"full_name\"]\n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_stac_metadata(basename, trait, description, in_meta):\n",
    "\n",
    "    out_meta = {}\n",
    "    out_meta['id'] = basename\n",
    "    out_meta['start_datetime'] = dt.datetime.strptime(in_meta['start_datetime'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    out_meta['end_datetime'] = dt.datetime.strptime(in_meta['end_datetime'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    out_meta['geometry'] = in_meta['geometry']\n",
    "    base_tokens = basename.split('_')\n",
    "    out_meta['collection'] = f\"SISTER_{base_tokens[1]}_{base_tokens[2]}_{base_tokens[3]}_{base_tokens[5]}\"\n",
    "    product = base_tokens[3]\n",
    "    if trait is not None:\n",
    "        product += f\"_{trait}\"\n",
    "    out_meta['properties'] = {\n",
    "        'sensor': in_meta['sensor'],\n",
    "        'description': description,\n",
    "        'product': product,\n",
    "        'processing_level': base_tokens[2]\n",
    "    }\n",
    "    return out_meta\n",
    "\n",
    "\n",
    "def create_item(metadata, assets):\n",
    "    item = pystac.Item(\n",
    "        id=metadata['id'],\n",
    "        datetime=metadata['start_datetime'],\n",
    "        start_datetime=metadata['start_datetime'],\n",
    "        end_datetime=metadata['end_datetime'],\n",
    "        geometry=metadata['geometry'],\n",
    "        collection=metadata['collection'],\n",
    "        bbox=None,\n",
    "        properties=metadata['properties']\n",
    "    )\n",
    "    # Add assets\n",
    "    for key, href in assets.items():\n",
    "        item.add_asset(key=key, asset=pystac.Asset(href=href))\n",
    "    return item\n",
    "\n",
    "\n",
    "def apply_trait_model(hy_obj, args):\n",
    "    '''Apply trait model(s) to image and export to file.\n",
    "\n",
    "    '''\n",
    "\n",
    "    logger.info(\"Applying Trait Model\")\n",
    "    print(\"Applying Trait Model\")\n",
    "    json_file,crid,disclaimer =args\n",
    "\n",
    "    with open(json_file, 'r') as json_obj:\n",
    "        trait_model = json.load(json_obj)\n",
    "        coeffs = np.array(trait_model['model']['coefficients']).T\n",
    "        intercept = np.array(trait_model['model']['intercepts'])\n",
    "        model_waves = np.array(trait_model['wavelengths'])\n",
    "\n",
    "    if (hy_obj.wavelengths.min() > model_waves.min()) |  (hy_obj.wavelengths.max() < model_waves.max()):\n",
    "        print('%s model wavelengths outside of image wavelength range, skipping....' % trait_model[\"full_name\"])\n",
    "        return\n",
    "\n",
    "    hy_obj.create_bad_bands([[300,400],[1337,1430],[1800,1960],[2450,2600]])\n",
    "    hy_obj.resampler['type'] = 'cubic'\n",
    "\n",
    "    #Check if wavelengths match\n",
    "    resample = not all(x in hy_obj.wavelengths for x in model_waves)\n",
    "    if resample:\n",
    "        print('Spectral resampling required')\n",
    "        hy_obj.resampler['out_waves'] = model_waves\n",
    "    else:\n",
    "        wave_mask = [np.argwhere(x==hy_obj.wavelengths)[0][0] for x in model_waves]\n",
    "\n",
    "    iterator = hy_obj.iterate(by = 'line',\n",
    "                  resample=resample)\n",
    "\n",
    "    trait_array = np.zeros((3,hy_obj.lines,\n",
    "                            hy_obj.columns))\n",
    "\n",
    "    while not iterator.complete:\n",
    "        chunk = iterator.read_next()\n",
    "        if not resample:\n",
    "            chunk = chunk[:,wave_mask]\n",
    "\n",
    "        # Apply spectrum transforms\n",
    "        for transform in  trait_model['model'][\"transform\"]:\n",
    "            if  transform== \"vector\":\n",
    "                norm = np.linalg.norm(chunk,axis=1)\n",
    "                chunk = chunk/norm[:,np.newaxis]\n",
    "            if transform == \"absorb\":\n",
    "                chunk = np.log(1/chunk)\n",
    "            if transform == \"mean\":\n",
    "                mean = chunk.mean(axis=1)\n",
    "                chunk = chunk/mean[:,np.newaxis]\n",
    "\n",
    "        trait_pred = np.dot(chunk,coeffs)\n",
    "        trait_pred = trait_pred + intercept\n",
    "        trait_mean = trait_pred.mean(axis=1)\n",
    "        qa = (trait_mean > trait_model['model_diagnostics']['min']) & (trait_mean < trait_model['model_diagnostics']['max'])\n",
    "\n",
    "        trait_array[0,iterator.current_line,:] = trait_mean\n",
    "        trait_array[1,iterator.current_line,:] = trait_pred.std(ddof=1,axis=1)\n",
    "        trait_array[2,iterator.current_line,:] = qa.astype(int)\n",
    "\n",
    "        nd_mask = hy_obj.mask['no_data'][iterator.current_line] & hy_obj.mask['veg'][iterator.current_line]\n",
    "        trait_array[:,iterator.current_line,~nd_mask] = -9999\n",
    "\n",
    "    trait_abbrv = trait_model[\"short_name\"].upper()\n",
    "    sister,sensor,level,product,datetime_var,in_crid =  hy_obj.base_name.split('_')\n",
    "\n",
    "    temp_file =  f'{temp_work_dir}/SISTER_{sensor}_L2B_VEGBIOCHEM_{datetime_var}_{crid}_{trait_abbrv}.tif'\n",
    "    out_file =  f'{output_stac_catalog_dir}/SISTER_{sensor}_L2B_VEGBIOCHEM_{datetime_var}_{crid}_{trait_abbrv}.tif'\n",
    "    \n",
    "\n",
    "    \n",
    "    logger.info(temp_file)\n",
    "    logger.info(out_file)\n",
    "\n",
    "    band_names = [\"%s_mean\" % trait_model[\"short_name\"].lower(),\n",
    "                                 \"%s_std_dev\" % trait_model[\"short_name\"].lower(),\n",
    "                                 \"%s_qa_mask\" % trait_model[\"short_name\"].lower()]\n",
    "\n",
    "    units= [trait_model[\"full_units\"].upper(),\n",
    "            trait_model[\"full_units\"].upper(),\n",
    "            \"NA\"]\n",
    "\n",
    "    descriptions= [\"%s MEAN\" % trait_model[\"full_name\"].upper(),\n",
    "                  \"%s STANDARD DEVIATION\" % trait_model[\"full_name\"].upper(),\n",
    "                  \"QUALITY ASSURANCE MASK\"]\n",
    "\n",
    "\n",
    "    in_file = gdal.Open(hy_obj.file_name)\n",
    "\n",
    "    # Set the output raster transform and projection properties\n",
    "    driver = gdal.GetDriverByName(\"GTIFF\")\n",
    "    tiff = driver.Create(temp_file,\n",
    "                         hy_obj.columns,\n",
    "                         hy_obj.lines,\n",
    "                         3,\n",
    "                         gdal.GDT_Float32)\n",
    "\n",
    "    tiff.SetGeoTransform(in_file.GetGeoTransform())\n",
    "    tiff.SetProjection(in_file.GetProjection())\n",
    "    tiff.SetMetadataItem(\"DESCRIPTION\",f\"{disclaimer}L2B VEGETATION BIOCHEMISTRY %s\" % trait_model[\"full_name\"].upper())\n",
    "\n",
    "    # Write bands to file\n",
    "    for i,band_name in enumerate(band_names,start=1):\n",
    "        band = tiff.GetRasterBand(i)\n",
    "        band.WriteArray(trait_array[i-1])\n",
    "        band.SetDescription(band_name)\n",
    "        band.SetNoDataValue(hy_obj.no_data)\n",
    "        band.SetMetadataItem(\"UNITS\",units[i-1])\n",
    "        band.SetMetadataItem(\"DESCRIPTION\",descriptions[i-1])\n",
    "    del tiff, driver\n",
    "\n",
    "    print(\"running system gdal commands\")\n",
    "\n",
    "    subprocess.run([f'{gdal_dir}/gdaladdo', \"-minsize\", \"900\", temp_file]) \n",
    "    #os.system(f\"gdaladdo -minsize 900 {temp_file}\")\n",
    "    subprocess.run([f'{gdal_dir}/gdal_translate', temp_file, out_file, \"-co\", \"COMPRESS=LZW\", \"-co\", \"TILED=YES\",\"-co\", \"COPY_SRC_OVERVIEWS=YES\"]) \n",
    "    #os.system(f\"gdal_translate {temp_file} {out_file} -co COMPRESS=LZW -co TILED=YES -co COPY_SRC_OVERVIEWS=YES\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e97444",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f614bb8e-8f44-404d-9c66-7c86022e2f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "if experimental:\n",
    "    logger.info(\"Turning on experimental flags\")\n",
    "    disclaimer = \"(DISCLAIMER: THIS DATA IS EXPERIMENTAL AND NOT INTENDED FOR SCIENTIFIC USE) \"\n",
    "else:\n",
    "    disclaimer = \"\"\n",
    "\n",
    "\n",
    "rfl_base_name = Path(reflectance_file).stem\n",
    "sister,sensor,level,product,datetime_var,in_crid = rfl_base_name.split('_')\n",
    "\n",
    "rfl_file = reflectance_file\n",
    "fc_file = frcov_file\n",
    "\n",
    "qlook_file = f'{output_stac_catalog_dir}/SISTER_{sensor}_L2B_VEGBIOCHEM_{datetime_var}_{crid}.png'\n",
    "qlook_met = qlook_file.replace('.png','.met.json')\n",
    "\n",
    "models = glob.glob('models/PLSR*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "241edbbd-2ad4-4164-9249-e074921a1a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 16:57:35,734\tWARNING services.py:1732 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=4.86gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-03-21 16:57:35,979\tINFO worker.py:1538 -- Started a local Ray instance.\n",
      "2024-03-21 16:57:37,203 INFO: Loading data\n",
      "2024-03-21 16:58:02,894 INFO: Setting fractional cover mask\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m Applying Trait Model\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m Applying Trait Model\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m Applying Trait Model\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m running system gdal commands\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m 0\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ...10\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ...20...30\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ...40...50...60...70.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ..80...90\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m .100 - done.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m Input file size is 2003, 1935\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m 0\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m 10\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m 20.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m .30..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m 40\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m .50\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ...\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m 60.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m 70.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m .80\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m ..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m 90...\n",
      "\u001b[2m\u001b[36m(HyTools pid=1066)\u001b[0m 100 - done.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m running system gdal commands\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m 0\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m ...10\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m ...20...30...40\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m ...50...60...70...80...90..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m running system gdal commands\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m 0\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m .100 - done.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m ...10...20...30...40...50.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m ..60...70...80...90..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m Input file size is 2003, 1935\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m 0\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m .100 - done.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m ..10.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m ..20.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m Input file size is 2003, 1935\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m 0.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m ..10\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m .30...40\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m ...\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m ...\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m 20\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m 50...\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m 60\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m ..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m ...70\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m 30...40\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m ...80.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m ...\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m ..90...\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m 50...60\n",
      "\u001b[2m\u001b[36m(HyTools pid=1064)\u001b[0m 100 - done.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m ...70.\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m ..80..\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m .\n",
      "\u001b[2m\u001b[36m(HyTools pid=1065)\u001b[0m 90...\n"
     ]
    }
   ],
   "source": [
    "if ray.is_initialized():\n",
    "    ray.shutdown()\n",
    "ray.init(num_cpus = len(models))\n",
    "\n",
    "HyTools = ray.remote(ht.HyTools)\n",
    "actors = [HyTools.remote() for rfl_file in models]\n",
    "\n",
    "# Load data\n",
    "logger.info(\"Loading data\")\n",
    "_ = ray.get([a.read_file.remote(rfl_file,'envi') for a,b in zip(actors,models)])\n",
    "\n",
    "# Set fractional cover mask\n",
    "logger.info(\"Setting fractional cover mask\")\n",
    "fc_obj = gdal.Open(fc_file)\n",
    "veg_mask = fc_obj.GetRasterBand(2).ReadAsArray() >= veg_cover\n",
    "\n",
    "_ = ray.get([a.set_mask.remote(veg_mask,'veg') for a,b in zip(actors,models)])\n",
    "\n",
    "_ = ray.get([a.do.remote(apply_trait_model,[json_file,crid,disclaimer]) for a,json_file in zip(actors,models)])\n",
    "\n",
    "ray.shutdown()\n",
    "\n",
    "bands = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85407d69-8ab2-40f1-b733-fe10c244e38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/unity/ads/outputs/SBG-L2B_VEGBIOCHEM/SISTER_EMIT_L2B_VEGBIOCHEM_20230807T182755_000_NIT.tif\n",
      "/unity/ads/outputs/SBG-L2B_VEGBIOCHEM/SISTER_EMIT_L2B_VEGBIOCHEM_20230807T182755_000_CHL.tif\n",
      "/unity/ads/outputs/SBG-L2B_VEGBIOCHEM/SISTER_EMIT_L2B_VEGBIOCHEM_20230807T182755_000_LMA.tif\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if sensor != 'DESIS':\n",
    "    for trait_abbrv in ['NIT','CHL','LMA']:\n",
    "        \n",
    "        tif_file = f'{output_stac_catalog_dir}/SISTER_{sensor}_L2B_VEGBIOCHEM_{datetime_var}_{crid}_{trait_abbrv}.tif'\n",
    "        print(tif_file)\n",
    "        gdal_obj = gdal.Open(tif_file)\n",
    "        band = gdal_obj.GetRasterBand(1)\n",
    "        band_arr = np.copy(band.ReadAsArray())\n",
    "        bands.append(band_arr)\n",
    "\n",
    "    rgb=  np.array(bands)\n",
    "    rgb[rgb == band.GetNoDataValue()] = np.nan\n",
    "\n",
    "    rgb = np.moveaxis(rgb,0,-1).astype(float)\n",
    "    bottom = np.nanpercentile(rgb,5,axis = (0,1))\n",
    "    top = np.nanpercentile(rgb,95,axis = (0,1))\n",
    "    rgb = np.clip(rgb,bottom,top)\n",
    "    rgb = (rgb-np.nanmin(rgb,axis=(0,1)))/(np.nanmax(rgb,axis= (0,1))-np.nanmin(rgb,axis= (0,1)))\n",
    "    rgb = (rgb*255).astype(np.uint8)\n",
    "    im = Image.fromarray(rgb)\n",
    "    description = f'{disclaimer}Vegetation biochemistry RGB quicklook. R: Nitrogen, G: Chlorophyll, B: Leaf Mass ' \\\n",
    "                  f'per Area'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33079c2e-7a8f-42ae-9ec5-174cb027d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.save(qlook_file)\n",
    "\n",
    "# If experimental, prefix filenames with \"EXPERIMENTAL-\"\n",
    "if experimental:\n",
    "    for file in glob.glob(f\"{output_stac_catalog_dir}/SISTER*\"):\n",
    "        shutil.move(file, f\"{output_stac_catalog_dir}/EXPERIMENTAL-{os.path.basename(file)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89224c4e",
   "metadata": {},
   "source": [
    "# Create stage-out item catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0fbd0dc-eb7f-4df1-aa8f-66329b62ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dataset = inp_collection.datasets[0]\n",
    "\n",
    "data_files = glob.glob(output_stac_catalog_dir+\"/*SISTER*.tif\") \n",
    "# hack to get the radiance file\n",
    "data_file = os.path.basename(data_files[0].replace(\"_UNC\",\"\"))\n",
    "name=os.path.splitext(data_file)[0]\n",
    "name = (\"_\").join(name.split(\"_\")[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4aa5d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    name=name, \n",
    "    collection_id=output_collection, \n",
    "    start_time=orig_dataset.data_begin_time, \n",
    "    end_time=orig_dataset.data_end_time,\n",
    "    creation_time=datetime.utcnow().replace(tzinfo=timezone.utc).isoformat(),\n",
    ")\n",
    "\n",
    "# Add output file(s) to the dataset\n",
    "for file in glob.glob(output_stac_catalog_dir+\"/*SISTER*\"):\n",
    "    #type, location, roles = [], title = \"\", description = \"\" \n",
    "    if file.endswith(\".tif\"):\n",
    "        dataset.add_data_file(DataFile(\"COG\",file, [\"data\"]))\n",
    "    elif file.endswith(\".png\"):\n",
    "        dataset.add_data_file(DataFile(\"image/png\",file, [\"browse\"]))\n",
    "    else:\n",
    "        dataset.add_data_file(DataFile(None,file, [\"metadata\"]))\n",
    "        \n",
    "#Add the STAC file we are creating\n",
    "# the future metadata file needs to be added to the STAC as well\n",
    "    # will eventually be moved into the to_stac() function\n",
    "dataset.add_data_file(DataFile(\"text/json\",os.path.join(output_stac_catalog_dir, name + \".json\"), [\"metadata\"]))\n",
    "\n",
    "# Add the dataset to the collection\n",
    "#out_collection.add_dataset(dataset)\n",
    "out_collection._datasets.append(dataset)\n",
    "\n",
    "Collection.to_stac(out_collection, output_stac_catalog_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f240b6-b5ea-4bf8-8764-ecf12eee6c16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
